---
title: "Lab-3-solution"
output:
  pdf_document: default
  html_document: default
date: "2024-10-02"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Task 1
Simply read the data and transform relevant variables to factors.
```{r message=FALSE}
dat_data = read_csv('data/ease2024/Run_Table_TPCH.csv')
dat_data$library = as.factor(dat_data$library)
dat_data$dataframe_size = as.factor(dat_data$dataframe_size)
dat_data$trial = as.factor(dat_data$trial)
```

## Task 2 & 3
We can utilize dplyr package and group_by feature to run all of the setups at once.
```{r, message=FALSE, warning=FALSE, results='hide'}
dat_data %>%
  group_by(library, dataframe_size) %>%
  group_split() %>%
  lapply(function(group_data) {
    hist(group_data$energy_usage, 
         main = unique(group_data$library), 
         xlab = "Energy usage")
  })
```
```{r}
dat_data %>%
  group_by(library, dataframe_size) %>%
  summarize(n = n(),
            stest = shapiro.test(energy_usage)$p.value)
```

## Task 4 & 5
We can see that even though we normalized data, it still doesn't hold assumptions for conditional normality - we have to be careful with normalization and understand when we can use it or not. We have to be extra careful when considering multiple factors.
```{r, message=FALSE, warning=FALSE, results='hide'}
library(bestNormalize)
dat_data$norm_energy_usage = bestNormalize(dat_data$energy_usage)$x.t
dat_data %>%
  group_by(library, dataframe_size) %>%
  group_split() %>%
  lapply(function(group_data) {
    hist(group_data$norm_energy_usage, 
         main = c(unique(group_data$library), unique(group_data$dataframe_size)), 
         xlab = "Energy usage")
  })
```
```{r}
dat_data %>%
  group_by(library, dataframe_size) %>%
  summarize(n = n(),
            stest = shapiro.test(norm_energy_usage)$p.value)
```

## Task 6

```{r, results='hide', message=FALSE}
pandas_small = dat_data[dat_data$dataframe_size == 'Small' & dat_data$library == 'Pandas',]$energy_usage
polars_small = dat_data[dat_data$dataframe_size == 'Small' & dat_data$library == 'Polars',]$energy_usage
wilcox.test(pandas_small, polars_small)

pandas_big = dat_data[dat_data$dataframe_size == 'Big' & dat_data$library == 'Pandas',]$energy_usage
polars_big = dat_data[dat_data$dataframe_size == 'Big' & dat_data$library == 'Polars',]$energy_usage
wilcox.test(pandas_big, polars_big)
```
We shall use Wilcoxon test; it's non-parametric and we can't use a parametric test as our data is not normal.

## Task 7
```{r}
library(ARTool)

model = art(energy_usage ~ library * dataframe_size + Error(trial), data = dat_data)
anova(model)
```
To check if model is correct we simpy run command
summary(model)
and investigate whether all F-values are 0.

anova(model) shows us information about influence of each variable and their interactions.

## Task 8
```{r, message=FALSE}
library(lmerTest)
model = lmer(norm_energy_usage ~ library * dataframe_size + (1|trial), data = dat_data)
anova(model)
```

We can investigate residuals of the mixed linear model with commands

```{r}
qqnorm(resid(model))
qqline(resid(model))
shapiro.test(resid(model))
```
We can see residuals are not normal, which might be the result that our data doesn't meet the conditional normality assumption, even though it's distribution with no regard to factors looks normal.
